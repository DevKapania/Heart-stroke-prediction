# â¤ï¸ Heart Stroke Risk Prediction

![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-189AB4?style=for-the-badge&logo=xgboost)
![Tableau](https://img.shields.io/badge/Tableau-E97627?style=for-the-badge&logo=tableau&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas)

> A machine learning pipeline that predicts **heart disease risk** in patients using clinical features â€” with Tableau dashboards for communicating insights to non-technical stakeholders.

---

## ðŸ«€ Project Overview

Cardiovascular disease is the leading cause of death globally. Early prediction and risk stratification can enable preventive care and significantly reduce mortality. This project builds and benchmarks multiple classification models to predict heart stroke risk based on patient clinical data, with a strong focus on **handling class imbalance**, **feature engineering**, and **explainability**.

---

## âš™ï¸ Features

- âœ… Comprehensive EDA with visual correlation analysis
- âœ… Feature engineering: encoding, scaling, interaction features
- âœ… Class imbalance handling using **SMOTE** (Synthetic Minority Oversampling)
- âœ… Benchmarked 3 models: Logistic Regression, Random Forest, XGBoost
- âœ… Hyperparameter tuning with GridSearchCV + Cross-Validation
- âœ… Evaluation: Precision, Recall, F1-Score, ROC-AUC (focus on minority class)
- âœ… Tableau dashboard for feature importance and risk score visualization

---

## ðŸ—‚ï¸ Project Structure

```
heart-stroke-prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Original dataset
â”‚   â””â”€â”€ processed/                  # Cleaned & SMOTE-balanced data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb                # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb      # Feature engineering & SMOTE
â”‚   â””â”€â”€ 03_modeling.ipynb           # Model training & comparison
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py               # Preprocessing pipeline
â”‚   â”œâ”€â”€ train.py                    # Training all 3 models
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluation metrics & plots
â”‚   â””â”€â”€ predict.py                  # Inference on new patient data
â”‚
â”œâ”€â”€ tableau/
â”‚   â””â”€â”€ heart_stroke_dashboard.twbx # Tableau workbook
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”œâ”€â”€ random_forest.pkl
â”‚   â””â”€â”€ xgboost_model.pkl
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ§  Models Compared

| Model               | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|---------------------|----------|-----------|--------|----------|---------|
| Logistic Regression | 78%      | 74%       | 71%    | 72%      | 0.83    |
| Random Forest       | 84%      | 81%       | 79%    | 80%      | 0.89    |
| **XGBoost**         | **87%**  | **85%**   | **83%**| **84%**  | **0.92**|

> âœ… XGBoost selected as final model based on F1-Score and ROC-AUC performance.

---

## ðŸ“Š Key Findings from EDA

- Age, cholesterol, resting blood pressure, and max heart rate are the strongest predictors
- Class imbalance: ~85% negative, ~15% positive â€” addressed using SMOTE
- Strong correlation between ST depression and heart disease risk
- Males in the dataset had higher incidence rates than females

---

## ðŸš€ Getting Started

### Prerequisites
```bash
pip install -r requirements.txt
```

### Run Training
```bash
python src/train.py
```

### Predict on New Data
```bash
python src/predict.py --input patient_data.csv
```

---

## ðŸ“¦ Requirements

```
scikit-learn>=1.0
xgboost
pandas
numpy
matplotlib
seaborn
imbalanced-learn   # for SMOTE
joblib
```

---

## ðŸ”„ Pipeline Overview

```
Raw Clinical Data (age, BP, cholesterol, etc.)
            â†“
EDA â†’ Correlation Analysis â†’ Outlier Detection
            â†“
Feature Engineering + Label Encoding + Scaling
            â†“
SMOTE â†’ Balanced Train/Test Split (80/20)
            â†“
Train: Logistic Regression | Random Forest | XGBoost
            â†“
Cross-Validation (5-Fold) + Hyperparameter Tuning
            â†“
Evaluation â†’ Best Model Selection (XGBoost)
            â†“
Tableau Dashboard â†’ Risk Score Visualization
```

---

## ðŸ“‰ Handling Class Imbalance

Without addressing class imbalance, models tend to predict the majority class (no disease) almost always â€” achieving high accuracy but poor recall on the minority (disease) class, which is clinically dangerous.

**Solution: SMOTE** â€” generates synthetic samples of the minority class in feature space, balancing the training set without losing data.

```python
from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X_train, y_train)
```

---

## ðŸ“Š Tableau Dashboard

The Tableau dashboard visualizes:
- Feature importance rankings
- Patient risk score distribution
- Age vs. risk correlation
- Model prediction confidence by demographic group

---

## ðŸ‘¤ Author

**Dev Kapania**  
B.Tech CSE (Big Data) â€” UPES  
Deep Learning Research Intern @ IIT Roorkee  
ðŸ“§ devkapania2003@gmail.com  
ðŸ”— [LinkedIn](https://linkedin.com/in/dev-kapania)

---

## ðŸ“„ License

This project is licensed under the MIT License.
